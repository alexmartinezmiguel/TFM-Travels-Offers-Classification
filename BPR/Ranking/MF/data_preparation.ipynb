{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we process the data to be used for training the BPR algorithm using the Matrix Factorization as the underlying model. It tries to learn the relation between users and items and make predictions based on similarities between them. In our problem, we have a clear issue: all the items, i.e. the offers, are in principle unique and therefore it is not possible to learn these user-item relations. In order to solve this problem, we propose to identify two offers as equal if the different transport modes cover the same length of the trip.  To simplify the problem, we only consider five different transportation modes: walk, bike,car,  public transport and long public transport.   Hence, a trip composed by car-walk-walk would be the same as another trip composed by walk-walk-car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to store the transportation mode for each one of the legs of all the trips alternatives (we will need to generate them from the leg alternatives). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_wit_n_digits(n):\n",
    "    range_start = 10**(n-1)\n",
    "    range_end = (10**n)-1\n",
    "    return random.randint(range_start, range_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_alternatives(legs):\n",
    "    \"\"\"This function returns all possible combinations of leg alternatives to form\n",
    "        trip alternatives. The input is a list containing the leg alternatives from\n",
    "        the routeRank dataset\"\"\"\n",
    "\n",
    "    trip_dict = dict()\n",
    "    trip_dict.setdefault('from', legs[0]['from'])\n",
    "    trip_dict.setdefault('to', legs[-1]['to'])\n",
    "    trip_dict.setdefault('date', legs[0]['date'])\n",
    "    trip_dict.setdefault('tripId', legs[0]['tripId'])\n",
    "    trip_dict.setdefault('places', {})\n",
    "    number_alternatives_trip = []\n",
    "    for trip in legs:\n",
    "        trip_dict['places'].update(trip['places'])\n",
    "        number_alternatives_trip.append(len(trip['alternatives']))\n",
    "    number_alternatives_trip.append(1)\n",
    "    number_alternatives = np.prod(number_alternatives_trip)\n",
    "    l = [[] for i in range(number_alternatives)]\n",
    "    trip_dict.setdefault('alternatives', l)\n",
    "    for j in range(len(legs)):\n",
    "        k = np.prod(number_alternatives_trip[j + 1:])\n",
    "        v = 0\n",
    "        for alternative in legs[j]['alternatives']:\n",
    "            for i in range(number_alternatives):\n",
    "                if i % np.prod(number_alternatives_trip[j:]) == 0:\n",
    "                    for m in range(k):\n",
    "                        trip_dict['alternatives'][i + m + v].append(alternative)\n",
    "            v += k\n",
    "    return trip_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "routerank_alternatives_1 = json.load(open('data/final1.json'))\n",
    "routerank_alternatives_2 = json.load(open('data/final2.json'))\n",
    "leg_alternatives = routerank_alternatives_1 + routerank_alternatives_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trips = []\n",
    "unique_requests_id = open('data/final_unique_resquests_ids.txt', 'r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 trips combined\n",
      "200 trips combined\n",
      "300 trips combined\n",
      "400 trips combined\n",
      "500 trips combined\n",
      "600 trips combined\n",
      "700 trips combined\n",
      "800 trips combined\n",
      "900 trips combined\n",
      "1000 trips combined\n",
      "1100 trips combined\n",
      "1200 trips combined\n",
      "1300 trips combined\n",
      "1400 trips combined\n",
      "1500 trips combined\n",
      "1600 trips combined\n",
      "1700 trips combined\n",
      "1800 trips combined\n",
      "1900 trips combined\n",
      "2000 trips combined\n",
      "2100 trips combined\n",
      "2200 trips combined\n",
      "2300 trips combined\n",
      "2400 trips combined\n",
      "2500 trips combined\n",
      "2600 trips combined\n",
      "2700 trips combined\n",
      "2800 trips combined\n",
      "2900 trips combined\n",
      "3000 trips combined\n",
      "3100 trips combined\n",
      "3200 trips combined\n",
      "3300 trips combined\n",
      "3400 trips combined\n",
      "3500 trips combined\n",
      "3600 trips combined\n",
      "3700 trips combined\n",
      "3800 trips combined\n",
      "3900 trips combined\n",
      "4000 trips combined\n",
      "4100 trips combined\n",
      "4200 trips combined\n",
      "4300 trips combined\n",
      "4400 trips combined\n",
      "4500 trips combined\n",
      "4600 trips combined\n",
      "4700 trips combined\n",
      "4800 trips combined\n",
      "4900 trips combined\n",
      "5000 trips combined\n",
      "5100 trips combined\n",
      "5200 trips combined\n",
      "5300 trips combined\n",
      "5400 trips combined\n",
      "5500 trips combined\n",
      "5600 trips combined\n",
      "5700 trips combined\n",
      "5800 trips combined\n",
      "5900 trips combined\n",
      "6000 trips combined\n",
      "6100 trips combined\n",
      "6200 trips combined\n",
      "6300 trips combined\n",
      "6400 trips combined\n",
      "6500 trips combined\n",
      "6600 trips combined\n",
      "6700 trips combined\n",
      "6800 trips combined\n",
      "6900 trips combined\n",
      "7000 trips combined\n",
      "7100 trips combined\n",
      "7200 trips combined\n",
      "7300 trips combined\n",
      "7400 trips combined\n",
      "7500 trips combined\n",
      "7600 trips combined\n",
      "7700 trips combined\n",
      "7800 trips combined\n",
      "7900 trips combined\n",
      "8000 trips combined\n",
      "8100 trips combined\n",
      "8200 trips combined\n",
      "8300 trips combined\n",
      "8400 trips combined\n",
      "8500 trips combined\n",
      "8600 trips combined\n",
      "8700 trips combined\n",
      "8800 trips combined\n",
      "8900 trips combined\n",
      "9000 trips combined\n",
      "9100 trips combined\n",
      "9200 trips combined\n",
      "9300 trips combined\n",
      "9400 trips combined\n",
      "9500 trips combined\n",
      "9600 trips combined\n",
      "9700 trips combined\n",
      "9800 trips combined\n",
      "9900 trips combined\n",
      "10000 trips combined\n",
      "10100 trips combined\n",
      "10200 trips combined\n",
      "10300 trips combined\n",
      "10400 trips combined\n",
      "10500 trips combined\n",
      "10600 trips combined\n",
      "10700 trips combined\n",
      "10800 trips combined\n",
      "10900 trips combined\n",
      "11000 trips combined\n",
      "11100 trips combined\n",
      "11200 trips combined\n",
      "11300 trips combined\n",
      "11400 trips combined\n",
      "11500 trips combined\n",
      "11600 trips combined\n",
      "11700 trips combined\n",
      "11800 trips combined\n",
      "11900 trips combined\n",
      "12000 trips combined\n",
      "12100 trips combined\n",
      "12200 trips combined\n",
      "12300 trips combined\n",
      "12400 trips combined\n",
      "12500 trips combined\n",
      "12600 trips combined\n",
      "12700 trips combined\n",
      "12800 trips combined\n",
      "12900 trips combined\n",
      "13000 trips combined\n",
      "13100 trips combined\n",
      "13200 trips combined\n",
      "13300 trips combined\n",
      "13400 trips combined\n",
      "13500 trips combined\n",
      "13600 trips combined\n",
      "13700 trips combined\n",
      "13800 trips combined\n",
      "13900 trips combined\n",
      "14000 trips combined\n",
      "14100 trips combined\n",
      "14200 trips combined\n",
      "14300 trips combined\n",
      "14400 trips combined\n",
      "14500 trips combined\n",
      "14600 trips combined\n",
      "14700 trips combined\n",
      "14800 trips combined\n",
      "14900 trips combined\n",
      "15000 trips combined\n",
      "15100 trips combined\n",
      "15200 trips combined\n",
      "15300 trips combined\n",
      "15400 trips combined\n",
      "15500 trips combined\n",
      "15600 trips combined\n",
      "15700 trips combined\n",
      "15800 trips combined\n"
     ]
    }
   ],
   "source": [
    "# generate the trip alternatives\n",
    "k = 1\n",
    "for unique_id in unique_requests_id[:-1]:\n",
    "    legs = []\n",
    "    for trip in leg_alternatives:\n",
    "        if trip['tripId'] == unique_id:\n",
    "            legs.append(trip)\n",
    "    if len(legs) < 8:\n",
    "        new_trips.append(combine_alternatives(legs))\n",
    "    else:\n",
    "        print(k)\n",
    "    if k % 100 == 0:\n",
    "        print('{k} trips combined'.format(k=k))\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the trip alternatives have been generated, we iterate over the legs of these offers to store the modes of transport (mapped into 5 different means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map transport modes\n",
    "dict_transport_modes = {\n",
    "    'train': 'pubtrans',\n",
    "    'taxi': 'pubtrans',\n",
    "    'change': 'pubtrans',\n",
    "    'bus': 'pubtrans',\n",
    "    'subway': 'pubtrans',\n",
    "    'tram': 'pubtrans',\n",
    "    'bikesharing': 'bike',\n",
    "    'carsharing': 'car',\n",
    "    'genericpubtrans': 'pubtrans',\n",
    "    'boat': 'longpubtrans',\n",
    "    'funicular': 'pubtrans'\n",
    "}\n",
    "\n",
    "def map_transport_modes(mode):\n",
    "    mode_mapped = dict_transport_modes.get(mode, None)\n",
    "    if mode_mapped is not None:\n",
    "        return mode_mapped\n",
    "    else:\n",
    "        return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "modes_offer = dict()\n",
    "modes_offer_list = list()\n",
    "\n",
    "for trips in new_trips: #this loop goes through the trips\n",
    "    trip = trips['alternatives']\n",
    "    for alternative in trip: #this loop goes through the alternatives (offers)\n",
    "        modes = list()\n",
    "        offer_id = random_wit_n_digits(16)\n",
    "        # modes_offer.setdefault(offer_id,list())\n",
    "        for segments in alternative:\n",
    "            for segment in segments['segments']: #this loop goes through the segments\n",
    "                for leg in segment['legs']: #this loop goes through the legs\n",
    "                    modes.append(map_transport_modes(leg['transport']))\n",
    "        modes_offer.setdefault(offer_id, modes)\n",
    "        modes_offer_list.append(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different offers: 385865\n"
     ]
    }
   ],
   "source": [
    "print('Number of different offers:', len(modes_offer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'car', 'car', 'car', 'walking']\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(modes_offer[4469980719646669])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, 80% of the offer is performed by car, while the other 20% on foot. All the offers with this combination will be considered as equals. For that, we convert the previous list into a vector containing the fraction of the trip covered by each transport mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_modes = {\n",
    "    'walking':0,\n",
    "    'car':1,\n",
    "    'bike':2,\n",
    "    'pubtrans':3,\n",
    "    'longpubtrans':4\n",
    "}\n",
    "\n",
    "# create the vectors containing the fraction of the trip covered by each transport mode\n",
    "modes_offer_vector = dict()\n",
    "for key, value in modes_offer.items():\n",
    "    modes_offer_vector.setdefault(key,np.empty(5))\n",
    "    temp_dict_modes = np.zeros(5)\n",
    "    k = 0\n",
    "    for mode in value:\n",
    "        temp_dict_modes[vector_modes[mode]] += 1\n",
    "        k += 1\n",
    "    modes_offer_vector[key] = list(temp_dict_modes/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.8, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(modes_offer_vector[4469980719646669])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to extract the unique vectors and assign an identification to each one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data = [list(x) for x in set(tuple(x) for x in list(modes_offer_vector.values()))]\n",
    "dict_unique_data = dict(zip(np.arange(1,len(unique_data)+1), unique_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different offers (based on fraction of the trip covered by each transport mode): 1030\n"
     ]
    }
   ],
   "source": [
    "print('Number of different offers (based on fraction of the trip covered by each transport mode):', len(dict_unique_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to map the original offer identification (unique) to the new identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key_from_value(val):\n",
    "    for key, value in dict_unique_data.items():\n",
    "        if val == value:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "offerid_2_new_id = dict()\n",
    "for key, value in modes_offer_vector.items():\n",
    "    new_id = find_key_from_value(value)\n",
    "    offerid_2_new_id.setdefault(key, new_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "offerid_2_new_id_df = pd.DataFrame(offerid_2_new_id, index=[0]).transpose().reset_index()\n",
    "offerid_2_new_id_df = offerid_2_new_id_df.rename(columns={'index':'offer_id',0:'id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to load the training set and change the offers identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../categorized_offers/trips_combined_final.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_fact = pd.merge(df, offerid_2_new_id_df, on='offer_id')[['request_id','user_id','id','Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "df_matrix_fact.to_csv('data/df_matrix_factorization.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
