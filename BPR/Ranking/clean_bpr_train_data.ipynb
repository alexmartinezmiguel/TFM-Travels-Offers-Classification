{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have computed the different category scores for the routeRANK dataset, we need to clean up a little bit the results. In particular, firstly we need to remove the mobility requests for which we did not find the actual trip in the routeRANK alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trip alternatives is a really heavy file and process it all at once is computationally hard. This is why we decided to do it in three different runs generating three different files that we need to merge now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_combined_1 = pd.read_csv('categorized_offers/df_combined_5000.csv')\n",
    "trips_combined_2 = pd.read_csv('categorized_offers/df_combined_5000_12100.csv')\n",
    "trips_combined_3 = pd.read_csv('categorized_offers/df_combined_12100_end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_id_no_alt_1 = open('categorized_offers/request_id_no_solution_5000.txt','r').read().split('\\n')\n",
    "trip_id_no_alt_2 = open('categorized_offers/request_id_no_solution_5000_12100.txt','r').read().split('\\n')\n",
    "trip_id_no_alt_3 = open('categorized_offers/request_id_no_solution_12100_end.txt','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_combined_total = pd.concat([trips_combined_1, trips_combined_2, trips_combined_3])\n",
    "trip_id_no_alt = trip_id_no_alt_1[:-1] + trip_id_no_alt_2[:-1] + trip_id_no_alt_3[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the offers with no actual trip in motiv\n",
    "cleaned_df = pd.DataFrame()\n",
    "for tripid in trips_combined_total.request_id.unique():\n",
    "    if tripid not in trip_id_no_alt:\n",
    "        trip_df = trips_combined_total[trips_combined_total['request_id']==tripid]\n",
    "        cleaned_df = pd.concat([cleaned_df, trip_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('categorized_offers/df_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to delete those mobility requests which only have one offer/alternative. The algorithm we want to implement (BPR) trains in a pair-wise fashion, and therefore works with pairs of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('categorized_offers/df_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique mobility requests:  15967\n"
     ]
    }
   ],
   "source": [
    "print('Unique mobility requests: ', cleaned_df.request_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the requests ids for which we only have 1 offer (we need to delete)\n",
    "counts = cleaned_df.groupby('request_id').count().sort_values('offer_id').reset_index()[['request_id','offer_id']]\n",
    "trips_ids_to_save = counts[counts['offer_id']>1]\n",
    "trips_combined_gt_1_offer = pd.merge(cleaned_df, trips_ids_to_save['request_id'], on='request_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique mobility requests:  15855\n"
     ]
    }
   ],
   "source": [
    "print('Unique mobility requests: ', trips_combined_gt_1_offer.request_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save the mobility requests identifications which will be actually used for the ranking algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_requests_ids = trips_combined_gt_1_offer.request_id.unique()\n",
    "np.savetxt('categorized_offers/final_unique_resquests_ids.txt', unique_requests_ids, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is to assign a unique identification to each offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint\n",
    "random.seed(0)\n",
    "def random_with_n_digits(N,n):\n",
    "    offer_ids = []\n",
    "    for _ in range(N):\n",
    "        range_start = 10 ** (n - 1)\n",
    "        range_end = (10 ** n) - 1\n",
    "        offer_ids.append(randint(range_start, range_end))\n",
    "    return offer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_offer_ids = random_with_n_digits(len(trips_combined_gt_1_offer), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the columns\n",
    "trips_combined_gt_1_offer.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1','offer_id'],\n",
    "                               axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the new offer identifiers\n",
    "trips_combined_gt_1_offer['offer_id'] = unique_offer_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, because of the way we have combined the leg alternatives to form the trip alternatives, there requests with too many offers (even more than 1000). For now, we will delete those requests because we will not use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the requests for which we have too many offers\n",
    "counts = trips_combined_gt_1_offer.groupby('request_id').count().sort_values('offer_id').reset_index()[['request_id','offer_id']]\n",
    "trips_ids_to_save = counts[counts['offer_id']<1000]\n",
    "df = pd.merge(trips_combined_gt_1_offer, trips_ids_to_save['request_id'], on='request_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique mobility requests:  15820\n"
     ]
    }
   ],
   "source": [
    "print('Unique mobility requests: ', df.request_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us change the user identification to a numeric values (right now it is a combination of characters) for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_ids_mapping(df):\n",
    "    # dataframe mapping the original ids to the new ones\n",
    "    convert_userid = list(zip(np.arange(1,len(df.user_id.unique())+1)\n",
    "                         ,df.user_id.unique()))\n",
    "    convert_userid_df = pd.DataFrame(data=convert_userid).rename(columns={0: 'new_user_id', 1: 'user_id'})\n",
    "    # merge to do perform the mapping\n",
    "    df2 = pd.merge(df, convert_userid_df, \n",
    "               on='user_id').drop(columns=['user_id'], axis=1).rename(columns={'new_user_id': 'user_id'})\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = user_ids_mapping(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('categorized_offers/trips_combined_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
